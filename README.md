# customsCrawer2016
A customs crawer and parser using `BeautifulSoup` in Python.

# Description
## Files
  - `2016may.htm` is the source code of the website from where we'd like to extract the data.
  - `paser.py` is the Python code we use to parse the `html` file.
  - `formatify.py` is the Python code we use to further organize the data from `paser.py`.
  - `results` is the folder of all the intermediate results. For some data, I did it with copy and paste. In other words, it is not a totoally automatic process. I copy the data I want (you can do this too at first. Because it makes things simpler, of course you can extract it with code) and paste it into a new txt or csv file, which later is used as the input for another code. This folder is just to given a sense of what the output looks like.
  - `README.md`, as the name suggests, is a brief manual.
  - `.gitignore` is for the management of this github repo, you can ignore it.
  
  
## Where to start
The whole process might takes you 3 to 7 hours, be patient. You can do it.
  1. Know some Python code. :stuck_out_tongue_closed_eyes: I would like to recommend [Google's Python Class](https://developers.google.com/edu/python/).
  2. Go to [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) and play a little bit with the examples. You will get a sense of what is going on.
  3. Run `paser.py` and see the output. Given you finished step 2, the code itself is short and easy. 
  4. The next step is to parse (damn, I had so many typos, never mind :relieved:, carry on) the data into the format you want. This is what `formatify.py` do, of course you can do better.
  5. Done. Buy me a beer next time we hang out, cheers :beers:.
